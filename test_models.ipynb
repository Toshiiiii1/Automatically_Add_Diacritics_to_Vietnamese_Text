{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Code\\Python Code\\CT208\\vm\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments, Seq2SeqTrainingArguments\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from datasets import load_metric\n",
    "import torch\n",
    "import numpy as np\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = AutoModelForSeq2SeqLM.from_pretrained(\"./3rd/checkpoint-25500\")\n",
    "model2 = AutoModelForSeq2SeqLM.from_pretrained(\"./4th/checkpoint-25500\")\n",
    "model3 = AutoModelForSeq2SeqLM.from_pretrained(\"./5th/checkpoint-34000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Câu gốc: Thích thú đứng theo dõi cả buổi, ông Adam Frank, một kỹ thuật viên về hưu, chia sẻ: \"Con trai tôi tập một chút jujitsu. Tôi không biết nhiều về võ thuật, nhưng xem họ biểu diễn rất đẹp. Tôi nghĩ võ thuật là nền tảng tốt cho trẻ em\".\n",
      "Câu không dấu: Thich thu dung theo doi ca buoi, ong Adam Frank, mot ky thuat vien ve huu, chia se: \"Con trai toi tap mot chut jujitsu. Toi khong biet nhieu ve vo thuat, nhung xem ho bieu dien rat dep. Toi nghi vo thuat la nen tang tot cho tre em\".\n",
      "model1: Thích thú đúng theo dõi cả buổi, ông Adam Frank, một kỹ thuật viên về hưu, chia sẻ: \"Con trai tôi tập một chút jujitsu. Tôi không biết nhiều về võ thuật, nhưng xem họ biểu diễn rất đẹp. Tôi nghĩ võ thuật là nền tảng tốt cho trẻ em\".\n",
      "model2: Thích thú đúng theo dõi cả buổi, ông Adam Frank, một kỹ thuật viên về hưu, chia sẻ: \"Con trai tôi tập một chút jujitsu. Tôi không biết nhiều về võ thuật, nhưng xem họ biểu diễn rất đẹp. Tôi nghĩ võ thuật là nền tảng tốt cho trẻ em\".\n",
      "model3: Thích thú đứng theo dõi cả buổi, ông Adam Frank, một kỹ thuật viên về hưu, chia sẻ: \"Con trai tôi tập một chút jujitsu. Tôi không biết nhiều về võ thuật, nhưng xem họ biểu diễn rất đẹp. Tôi nghĩ võ thuật là nền tảng tốt cho trẻ em\".\n"
     ]
    }
   ],
   "source": [
    "sentence = input()\n",
    "print(f\"Câu gốc: {sentence}\", end=\"\\n\")\n",
    "sentence = unidecode(sentence)\n",
    "print(f\"Câu không dấu: {sentence}\", end=\"\\n\")\n",
    "\n",
    "encoding = tokenizer(sentence, return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "output1 = model1.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    max_length=1024,\n",
    ")\n",
    "\n",
    "output2 = model2.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    max_length=1024,\n",
    ")\n",
    "\n",
    "output3 = model3.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    max_length=1024,\n",
    ")\n",
    "\n",
    "for output in output1:\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    print(f\"model1: {line}\", end=\"\\n\")\n",
    "    \n",
    "for output in output2:\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    print(f\"model2: {line}\", end=\"\\n\")\n",
    "    \n",
    "for output in output3:\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    print(f\"model3: {line}\", end=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
