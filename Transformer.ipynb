{"cells":[{"cell_type":"markdown","metadata":{"id":"tcmYh1-n8vFr"},"source":["# Setup"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2616,"status":"ok","timestamp":1707740144557,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"5_uOXRoK679P","outputId":"42f0ebee-14b6-4b95-f708-d9422f6f269e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"eE1hHegMzV2Y","executionInfo":{"status":"ok","timestamp":1707740185468,"user_tz":-420,"elapsed":40914,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"}}},"outputs":[],"source":["%%capture\n","!pip install datasets evaluate transformers\n","!pip install rouge_score\n","!pip install accelerate"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"0k0a9jYh1N8h","executionInfo":{"status":"ok","timestamp":1707740204129,"user_tz":-420,"elapsed":18668,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"}}},"outputs":[],"source":["from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments, Seq2SeqTrainingArguments\n","from tqdm.notebook import tqdm\n","from torch.utils.data import DataLoader\n","import pandas as pd\n","from datasets import load_metric\n","import torch\n","import numpy as np"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["23b36407decb4f3a8204b44763bf14a7","3d9134c5f8d04c0f859f2a9aee60c94b","3a3c8d88cf5d4fc2a9802381b43194ca","c30ab84b37ee4a1ba51140057bb07d75","ac9ab03aaa224ea5bfa4f0c39bfdb5b0","30bbaa98aae643f6b9f0606fb7d3dfc3","d0964606bea24d6dbbd4f13f1ff6376c","a071e0575b624fb79318446d59272f7d","74a41d102c814b548c5e063719c97d61","33f9200a2e7a4639bfec0aa755a940fd","8636444807db42b48ecf47fa515810be","f4dd94c82d84421c8f1dfcef6670132b","5e78489760804f33a7756bb15495f21d","59055d0b2a944b5b9841c22729165ac2","4a9c7019baa0445db29dc66d4c814846","8237e0b20a524d72bf54b9ae98a5372f","7c3a02f2f48042bd88b4cece05f82ead","1e63a97979e44b92b7cad63dc9196dcd","42c93bc1554e4df3b6c7aac7812dd7b0","4cbdd04057cf455da1a0c070b5a78c5d","c008fff625ed45c6a00ab61560e71c9b","1f4c304bc9f949d6981c1622ce33cdde","d6f15ce69744461fbf48ff7718583466","97802713e8864dc3bf92fef59376b259","e2657f8d8e354ac180ada4d48eaec39c","877f32eb8ea3440eb1b756ff05e1879d","522daf0d3d1145ebaed1dc833bc9cebf","032c8b2aba674dd1b27b3f91cf9876cc","bf336e25d63e4bfc915a7929b74aabfb","4afdea8e2e7d438d8409ed1368c4d6e1","04a3e793d49c44cb8af2d1937db50787","a11ceed26bad4fc293d828b10b8d622b","5fb2d81266f84e86bdaa4791983be8ca","9711f4fd0ab345c3993a47c1c9725842","8905de6a24bc467da3d238097a8b48af","c87de47fb08342e49c583d5c0d9b970f","ad8d4bd685f34c17848e70311a90f784","b6c4f36afa234d83b9ab45196d513144","bd9874f60840466b8dcbe0c35bf584e7","c40d7f0b323343199e3c01475803e4a4","19bf55d6b492439095e54d2722f930a0","43136350163d4b17a7b998a3907e5839","203cfb274ca344e488d25e8b43d47e6a","f7d41dc84303451e852d9b1526b9a9c1","c2231b553a9b434cabce3a7e9d313bd0","ece6b37de2d0422a9fd7a6350b9ba162","ec632f25cf0b4269a28fe8deb2e4bd56","6e763c4681ea4035be18aba062433d75","8fa9c6d30c684343b0593d908165b113","a7c6dfdac5b64f088585782f4971059b","92610853e87a46b8832e779ea3cac671","2026774db6684c05ac75a71aa8ffc35b","fd3ac9c65b4e42a3afe26ca2d6a31f60","338c2a94269c452daa75906779a64869","f4690be6020c4e828ca3c2e22192ba09","b57d754d09d6484ba1a1f0d36bcce051","1f4a6dbc33cc4277abf78338061e3f17","38abb0b97d564d139169acfa9b196cb9","8f2b971cb30d451ea960f5921044d37a","43fe76e200b24a7da318dd450a78b473","2d23961bc83e4c86843e3809077cb6ea","f3e02b3ce3b84a55953e8d5c610aba4f","b3b5f4e32e964bc9b8a3977cb60c1b35","6b50ad3562414b468127f31424cdbf70","3e1504db86cd403a8fd5d7713ce7a9a4","9baca84aba88425e972f863b6cbb6696"]},"id":"FSflnvY21VHZ","executionInfo":{"status":"ok","timestamp":1707740227057,"user_tz":-420,"elapsed":22936,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"}},"outputId":"92489cc5-8bc9-47f5-d494-c4cdea925674"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23b36407decb4f3a8204b44763bf14a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/820k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4dd94c82d84421c8f1dfcef6670132b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/2.40M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6f15ce69744461fbf48ff7718583466"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9711f4fd0ab345c3993a47c1c9725842"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2231b553a9b434cabce3a7e9d313bd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/904M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b57d754d09d6484ba1a1f0d36bcce051"}},"metadata":{}}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/vit5-base\")\n","# model.to('cuda')"]},{"cell_type":"markdown","metadata":{"id":"8vNJeGsb84qd"},"source":["# Preprocessing data"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"mZc5goJX4ozS","executionInfo":{"status":"ok","timestamp":1707740624480,"user_tz":-420,"elapsed":373,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"}}},"outputs":[],"source":["def preprocess_function(examples):\n","    model_inputs = tokenizer(\n","        examples[\"inputs\"], max_length=300, truncation=True, padding=True\n","    )\n","\n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(\n","            examples[\"labels\"], max_length=300, truncation=True, padding=True\n","        )\n","    model_inputs['labels'] = labels['input_ids']\n","    model_inputs['input_ids'] = model_inputs['input_ids']\n","    return model_inputs"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"w4g_B7m6CoLn","colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"status":"error","timestamp":1707740625029,"user_tz":-420,"elapsed":7,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"}},"outputId":"78d600be-f05e-4b30-dd1e-2561b1e64bf8"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'pd' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-cd0f3660cc87>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/CT208/Data/train_set.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"str\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/CT208/Data/val_set.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/CT208/Data/test_set.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["train_set = pd.read_csv(\"/content/drive/MyDrive/CT208/Data/train_set.csv\").astype(\"str\")\n","val_set = pd.read_csv(\"/content/drive/MyDrive/CT208/Data/val_set.csv\")\n","test_set = pd.read_csv(\"/content/drive/MyDrive/CT208/Data/test_set.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mbwORjFT9wbt","executionInfo":{"status":"aborted","timestamp":1707740625030,"user_tz":-420,"elapsed":5,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"}}},"outputs":[],"source":["def tokenize(data):\n","    input_lines = data.iloc[:, 0].to_numpy()\n","    label_lines = data.iloc[:, 1].to_numpy()\n","    dict_obj = {'inputs': input_lines, 'labels': label_lines}\n","    dataset = Dataset.from_dict(dict_obj)\n","    tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=10)\n","\n","    return tokenized_datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1707740625030,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"QQujZ_iJ-Rpd"},"outputs":[],"source":["tokenized_train_set = tokenize(train_set)\n","tokenized_val_set = tokenize(val_set)\n","tokenized_test_set = tokenize(test_set)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gct1eihfDWyj","executionInfo":{"status":"aborted","timestamp":1707740625031,"user_tz":-420,"elapsed":1285,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"}}},"outputs":[],"source":["print(len(tokenized_train_set))\n","print(len(tokenized_val_set))\n","print(len(tokenized_test_set))"]},{"cell_type":"markdown","metadata":{"id":"1LYWuj6l9XYk"},"source":["# Draft"]},{"cell_type":"markdown","metadata":{"id":"MY44BLZgXybu"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6a6gf_ZjCZB"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n","\n","training_args = Seq2SeqTrainingArguments(\"/content/drive/MyDrive/CT208/1st\",\n","                                      do_train=True,\n","                                      do_eval=False,\n","                                      num_train_epochs=30,\n","                                      learning_rate=1e-5,\n","                                      warmup_ratio=0.05,\n","                                      weight_decay=0.01,\n","                                      per_device_train_batch_size=4,\n","                                      per_device_eval_batch_size=4,\n","                                      logging_dir='./log',\n","                                      group_by_length=True,\n","                                      save_strategy=\"epoch\",\n","                                      save_total_limit=3,\n","                                      #eval_steps=1,\n","                                      #evaluation_strategy=\"steps\",\n","                                      # evaluation_strategy=\"no\",\n","                                      fp16=True,\n","                                      )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train_set,\n","    data_collator=data_collator,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LDo9N-EwsWyp"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"t2ayW4xAX0x0"},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZCEfh7ef6KY"},"outputs":[],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/CT208/1st/checkpoint-22500\")\n","model.to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9UxTrT_YgkuY"},"outputs":[],"source":["metrics = load_metric('rouge')\n","\n","max_target_length = 300\n","dataloader = torch.utils.data.DataLoader(tokenized_val_set, collate_fn=data_collator, batch_size=32)\n","\n","predictions = []\n","references = []\n","for i, batch in enumerate(tqdm(dataloader)):\n","    outputs = model.generate(\n","        input_ids=batch['input_ids'].to('cuda'),\n","        max_length=max_target_length,\n","        attention_mask=batch['attention_mask'].to('cuda'),\n","    )\n","    with tokenizer.as_target_tokenizer():\n","        outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n","\n","        labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n","        actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n","    predictions.extend(outputs)\n","    references.extend(actuals)\n","    metrics.add_batch(predictions=outputs, references=actuals)\n","\n","\n","metrics.compute()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bR3pOKyYltnm"},"outputs":[],"source":["[{k: v.mid.fmeasure} for k,v in metrics.compute(predictions=predictions, references=references).items()]"]},{"cell_type":"markdown","metadata":{"id":"vakA7VPCX7O-"},"source":["## Generate text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELjRg1h1mFHg"},"outputs":[],"source":["sentence = \"Các giá trị 'rouge-1,' 'rouge-2,' 'rouge-L,' và 'rouge-Lsum' là các phương pháp đánh giá chất lượng của các hệ thống tạo ra các văn bản tóm tắt. Đây là các độ đo phổ biến trong lĩnh vực xử lý ngôn ngữ tự nhiên và tóm tắt máy học.\"\n","text =  sentence + \" </s>\"\n","encoding = tokenizer(text, return_tensors=\"pt\")\n","input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n","outputs = model.generate(\n","    input_ids=input_ids, attention_mask=attention_masks,\n","    max_length=300,\n","    early_stopping=True\n",")\n","for output in outputs:\n","    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","    print(line)"]},{"cell_type":"markdown","metadata":{"id":"BZNsOK03DojH"},"source":["# 1st"]},{"cell_type":"markdown","metadata":{"id":"RZSy1mBFDojT"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RVT-Ep2MDojT"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n","\n","training_args = Seq2SeqTrainingArguments(output_dir=\"tmp/\",\n","                                      do_train=True,\n","                                      do_eval=True,\n","                                      num_train_epochs=30,\n","                                      learning_rate=1e-5,\n","                                      warmup_ratio=0.05,\n","                                      weight_decay=0.01,\n","                                      per_device_train_batch_size=4,\n","                                      per_device_eval_batch_size=4,\n","                                      logging_dir='./log',\n","                                      group_by_length=True,\n","                                      save_strategy=\"epoch\",\n","                                      save_total_limit=1,\n","                                      evaluation_strategy=\"epoch\",\n","                                      fp16=True,\n","                                      )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train_set,\n","    data_collator=data_collator,\n","    eval_dataset=tokenized_val_set\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":4391701,"status":"error","timestamp":1707212900552,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"j5ZLjPoHDojT","outputId":"e7e6cad7-d05c-4dd2-f71f-6fc0305cdfcb"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='15001' max='22500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [15001/22500 1:12:49 < 36:24, 3.43 it/s, Epoch 20/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.003900</td>\n","      <td>0.088920</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.004000</td>\n","      <td>0.093458</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.003800</td>\n","      <td>0.091270</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.003100</td>\n","      <td>0.094107</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.002300</td>\n","      <td>0.095836</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.002100</td>\n","      <td>0.097693</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.002400</td>\n","      <td>0.094863</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.001800</td>\n","      <td>0.094528</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.001700</td>\n","      <td>0.094873</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.001800</td>\n","      <td>0.096007</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.001500</td>\n","      <td>0.094003</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.001200</td>\n","      <td>0.094744</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.001100</td>\n","      <td>0.093991</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.000900</td>\n","      <td>0.094054</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.001000</td>\n","      <td>0.094948</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.000800</td>\n","      <td>0.092805</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>0.000700</td>\n","      <td>0.093396</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>0.000800</td>\n","      <td>0.095243</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>0.000700</td>\n","      <td>0.093988</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>0.000700</td>\n","      <td>0.094563</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1936\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1937\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2282\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2385\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_deepspeed_enabled\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfsdp\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fsdp_enabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2386\u001b[0m             \u001b[0;31m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2387\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2389\u001b[0m         \u001b[0;31m# Save SCHEDULER & SCALER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"GY37m9wgDojT"},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6220,"status":"ok","timestamp":1707213119739,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"gr4DLYozDojU","outputId":"f85706fe-3544-455c-a6f3-ce3dc2435194"},"outputs":[{"data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(36096, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/tmp/checkpoint-15000\")\n","model.to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"elapsed":92363,"status":"ok","timestamp":1707213335993,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"7-51Ag4tDojU","outputId":"90fafef5-ca0a-4580-c16e-16e59545eacc"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-22-4a8b4e0b284a>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metrics = load_metric('rouge')\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fa87d6663ea4f9b9672d9927044898a","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10db9795750f4875bc26021bc02f7a66","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"text/plain":["{'rouge1': AggregateScore(low=Score(precision=0.9697815817270669, recall=0.9649854988936158, fmeasure=0.9671411094961017), mid=Score(precision=0.9727936207335566, recall=0.968095967381642, fmeasure=0.9700114273291586), high=Score(precision=0.9756581854340024, recall=0.9711486167475941, fmeasure=0.9728402048995053)),\n"," 'rouge2': AggregateScore(low=Score(precision=0.9475699001744455, recall=0.9428342865191611, fmeasure=0.9449278929941518), mid=Score(precision=0.9525957043810401, recall=0.9480341669488486, fmeasure=0.9499068165659356), high=Score(precision=0.9567887374436481, recall=0.9527548819803037, fmeasure=0.9542870401165016)),\n"," 'rougeL': AggregateScore(low=Score(precision=0.9667994457184388, recall=0.9619037732888849, fmeasure=0.9640355081020906), mid=Score(precision=0.9701182577607471, recall=0.9655068392826804, fmeasure=0.9674139893836349), high=Score(precision=0.9732413702777974, recall=0.9687075037777059, fmeasure=0.9705334693640532)),\n"," 'rougeLsum': AggregateScore(low=Score(precision=0.96693416989213, recall=0.9619615570394094, fmeasure=0.9640155609507367), mid=Score(precision=0.9702158580029074, recall=0.9655331040384035, fmeasure=0.9674806461226331), high=Score(precision=0.9732489824798697, recall=0.9686991406050612, fmeasure=0.9704933758547908))}"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["metrics = load_metric('rouge')\n","\n","max_target_length = 300\n","dataloader = torch.utils.data.DataLoader(tokenized_test_set, collate_fn=data_collator, batch_size=32)\n","\n","predictions = []\n","references = []\n","for i, batch in enumerate(tqdm(dataloader)):\n","    outputs = model.generate(\n","        input_ids=batch['input_ids'].to('cuda'),\n","        max_length=max_target_length,\n","        attention_mask=batch['attention_mask'].to('cuda'),\n","    )\n","    with tokenizer.as_target_tokenizer():\n","        outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n","\n","        labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n","        actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n","    predictions.extend(outputs)\n","    references.extend(actuals)\n","    metrics.add_batch(predictions=outputs, references=actuals)\n","\n","\n","metrics.compute()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5069,"status":"ok","timestamp":1707213345528,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"2PJlo3CjDojU","outputId":"54aecb94-f593-438b-e812-b974551a0fef"},"outputs":[{"data":{"text/plain":["[{'rouge1': 0.9700114273291586},\n"," {'rouge2': 0.9499068165659356},\n"," {'rougeL': 0.9674139893836349},\n"," {'rougeLsum': 0.9674806461226331}]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["[{k: v.mid.fmeasure} for k,v in metrics.compute(predictions=predictions, references=references).items()]"]},{"cell_type":"markdown","metadata":{"id":"vEvJu1qxDojU"},"source":["## Generate text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2565,"status":"ok","timestamp":1707213457067,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"Cp2qvHDNDojU","outputId":"0bc1476e-2dfc-4b42-e569-be4a79656487"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ngày 5 2 ban tổ chức cuộc thi Thu hoạch Vesuvius đã trao giải thưởng trị giá 700 000 USD cho 3 nhà nghiên cứu về thành tựu ứng dụng trí tuệ nhân tạo AI để giải mã thông tin trong cuốn sách 2 000 năm tuổi bị cháy sém trong vụ cháy rừng núi Vesuvius chọn vui thành phố La Mã cổ đại Pompeii \n"]}],"source":["sentence = \"Ngay 5 2 ban to chuc cuoc thi Thu thach Vesuvius da trao giai thuong tri gia 700 000 USD cho 3 nha nghien cuu ve thanh tuu ung dung tri tue nhan tao AI de giai ma thong tin trong cuon giay 2 000 nam tuoi bi chay sem trong vu phun trao nui lua Vesuvius chon vui thanh pho La Ma co dai Pompeii\"\n","text =  sentence + \" </s>\"\n","encoding = tokenizer(text, return_tensors=\"pt\")\n","input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n","outputs = model.generate(\n","    input_ids=input_ids, attention_mask=attention_masks,\n","    max_length=300,\n","    early_stopping=True\n",")\n","for output in outputs:\n","    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","    print(line)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":397,"status":"error","timestamp":1707213879441,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"5wTCtuvz4BpZ","outputId":"988f6365-ca94-49c3-e984-391d893e681b"},"outputs":[{"ename":"NotImplementedError","evalue":"A UTF-8 locale is required. Got ANSI_X3.4-1968","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-93006f0e5237>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls -l'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n","\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"]}],"source":[]},{"cell_type":"markdown","metadata":{"id":"Qip-qrmeOu4s"},"source":["# 2nd"]},{"cell_type":"markdown","metadata":{"id":"SWptVibrOu42"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"63R6akGWOu42"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n","\n","training_args = Seq2SeqTrainingArguments(output_dir=\"tmp/\",\n","                                      do_train=True,\n","                                      do_eval=True,\n","                                      num_train_epochs=20,\n","                                      learning_rate=1e-5,\n","                                      warmup_ratio=0.05,\n","                                      weight_decay=0.01,\n","                                      per_device_train_batch_size=8,\n","                                      per_device_eval_batch_size=8,\n","                                      logging_dir='./log',\n","                                      group_by_length=True,\n","                                      save_strategy=\"epoch\",\n","                                      save_total_limit=1,\n","                                      evaluation_strategy=\"epoch\",\n","                                      fp16=True,\n","                                      )\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train_set,\n","    data_collator=data_collator,\n","    eval_dataset=tokenized_val_set\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":577},"id":"j2WmuRAmOu42","outputId":"7103361e-9e41-413b-85c8-eff318da1dfb"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='49265' max='58180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [49265/58180 5:35:46 < 1:00:45, 2.45 it/s, Epoch 16.94/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.284200</td>\n","      <td>0.140286</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.089200</td>\n","      <td>0.049880</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.050200</td>\n","      <td>0.031450</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.035900</td>\n","      <td>0.024392</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.025200</td>\n","      <td>0.020294</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.020200</td>\n","      <td>0.018651</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.016500</td>\n","      <td>0.017259</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.012900</td>\n","      <td>0.016916</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.010500</td>\n","      <td>0.016079</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.008900</td>\n","      <td>0.015936</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>0.007500</td>\n","      <td>0.015952</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>0.006500</td>\n","      <td>0.015887</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>0.005700</td>\n","      <td>0.015565</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>0.004700</td>\n","      <td>0.016043</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>0.004700</td>\n","      <td>0.016178</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>0.003800</td>\n","      <td>0.016129</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"PR9YdlSTOu43"},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6220,"status":"ok","timestamp":1707213119739,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"NbgxR_2ZOu43","outputId":"f85706fe-3544-455c-a6f3-ce3dc2435194"},"outputs":[{"data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(36096, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/tmp/checkpoint-15000\")\n","model.to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"elapsed":92363,"status":"ok","timestamp":1707213335993,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"6MSpQ3oNOu44","outputId":"90fafef5-ca0a-4580-c16e-16e59545eacc"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-22-4a8b4e0b284a>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metrics = load_metric('rouge')\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0fa87d6663ea4f9b9672d9927044898a","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"10db9795750f4875bc26021bc02f7a66","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/32 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"text/plain":["{'rouge1': AggregateScore(low=Score(precision=0.9697815817270669, recall=0.9649854988936158, fmeasure=0.9671411094961017), mid=Score(precision=0.9727936207335566, recall=0.968095967381642, fmeasure=0.9700114273291586), high=Score(precision=0.9756581854340024, recall=0.9711486167475941, fmeasure=0.9728402048995053)),\n"," 'rouge2': AggregateScore(low=Score(precision=0.9475699001744455, recall=0.9428342865191611, fmeasure=0.9449278929941518), mid=Score(precision=0.9525957043810401, recall=0.9480341669488486, fmeasure=0.9499068165659356), high=Score(precision=0.9567887374436481, recall=0.9527548819803037, fmeasure=0.9542870401165016)),\n"," 'rougeL': AggregateScore(low=Score(precision=0.9667994457184388, recall=0.9619037732888849, fmeasure=0.9640355081020906), mid=Score(precision=0.9701182577607471, recall=0.9655068392826804, fmeasure=0.9674139893836349), high=Score(precision=0.9732413702777974, recall=0.9687075037777059, fmeasure=0.9705334693640532)),\n"," 'rougeLsum': AggregateScore(low=Score(precision=0.96693416989213, recall=0.9619615570394094, fmeasure=0.9640155609507367), mid=Score(precision=0.9702158580029074, recall=0.9655331040384035, fmeasure=0.9674806461226331), high=Score(precision=0.9732489824798697, recall=0.9686991406050612, fmeasure=0.9704933758547908))}"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["metrics = load_metric('rouge')\n","\n","max_target_length = 300\n","dataloader = torch.utils.data.DataLoader(tokenized_test_set, collate_fn=data_collator, batch_size=32)\n","\n","predictions = []\n","references = []\n","for i, batch in enumerate(tqdm(dataloader)):\n","    outputs = model.generate(\n","        input_ids=batch['input_ids'].to('cuda'),\n","        max_length=max_target_length,\n","        attention_mask=batch['attention_mask'].to('cuda'),\n","    )\n","    with tokenizer.as_target_tokenizer():\n","        outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n","\n","        labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n","        actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n","    predictions.extend(outputs)\n","    references.extend(actuals)\n","    metrics.add_batch(predictions=outputs, references=actuals)\n","\n","\n","metrics.compute()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5069,"status":"ok","timestamp":1707213345528,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"dioBXs04Ou44","outputId":"54aecb94-f593-438b-e812-b974551a0fef"},"outputs":[{"data":{"text/plain":["[{'rouge1': 0.9700114273291586},\n"," {'rouge2': 0.9499068165659356},\n"," {'rougeL': 0.9674139893836349},\n"," {'rougeLsum': 0.9674806461226331}]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["[{k: v.mid.fmeasure} for k,v in metrics.compute(predictions=predictions, references=references).items()]"]},{"cell_type":"markdown","metadata":{"id":"S4k8UjK5Ou44"},"source":["## Generate text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2565,"status":"ok","timestamp":1707213457067,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"uy-MwoPzOu44","outputId":"0bc1476e-2dfc-4b42-e569-be4a79656487"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ngày 5 2 ban tổ chức cuộc thi Thu hoạch Vesuvius đã trao giải thưởng trị giá 700 000 USD cho 3 nhà nghiên cứu về thành tựu ứng dụng trí tuệ nhân tạo AI để giải mã thông tin trong cuốn sách 2 000 năm tuổi bị cháy sém trong vụ cháy rừng núi Vesuvius chọn vui thành phố La Mã cổ đại Pompeii \n"]}],"source":["sentence = \"Ngay 5 2 ban to chuc cuoc thi Thu thach Vesuvius da trao giai thuong tri gia 700 000 USD cho 3 nha nghien cuu ve thanh tuu ung dung tri tue nhan tao AI de giai ma thong tin trong cuon giay 2 000 nam tuoi bi chay sem trong vu phun trao nui lua Vesuvius chon vui thanh pho La Ma co dai Pompeii\"\n","text =  sentence + \" </s>\"\n","encoding = tokenizer(text, return_tensors=\"pt\")\n","input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n","outputs = model.generate(\n","    input_ids=input_ids, attention_mask=attention_masks,\n","    max_length=300,\n","    early_stopping=True\n",")\n","for output in outputs:\n","    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","    print(line)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":397,"status":"error","timestamp":1707213879441,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"sAwYIEBqOu44","outputId":"988f6365-ca94-49c3-e984-391d893e681b"},"outputs":[{"ename":"NotImplementedError","evalue":"A UTF-8 locale is required. Got ANSI_X3.4-1968","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-93006f0e5237>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls -l'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m       raise NotImplementedError(\n\u001b[0m\u001b[1;32m    169\u001b[0m           \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m       )\n","\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"]}],"source":[]},{"cell_type":"markdown","metadata":{"id":"_jzJR92p6bdJ"},"source":["# 3rd"]},{"cell_type":"markdown","metadata":{"id":"iUl8Ar626bdU"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LTBgt4676bdU"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"tmp/\",\n","    do_train=True,\n","    do_eval=True,\n","    num_train_epochs=10,\n","    learning_rate=1e-5,\n","    warmup_ratio=0.05,\n","    weight_decay=0.01,\n","    prediction_loss_only = True,\n","    gradient_accumulation_steps = 3,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    logging_dir='./log',\n","    group_by_length=True,\n","    save_strategy=\"epoch\",\n","    save_total_limit=1,\n","    evaluation_strategy=\"epoch\",\n","    fp16=True,\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train_set,\n","    data_collator=data_collator,\n","    eval_dataset=tokenized_val_set\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"elapsed":8863955,"status":"ok","timestamp":1707374521098,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"5Ximj8Nz6bdV","outputId":"b4db41d2-675c-4acb-f45b-a5b0b73553b9"},"outputs":[{"name":"stderr","output_type":"stream","text":["You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='9690' max='9690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9690/9690 2:27:34, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>4.343900</td>\n","      <td>0.178067</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>0.189600</td>\n","      <td>0.080621</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.075700</td>\n","      <td>0.042908</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.059900</td>\n","      <td>0.036802</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.043500</td>\n","      <td>0.030427</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.040600</td>\n","      <td>0.028967</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.035800</td>\n","      <td>0.027902</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=9690, training_loss=0.3022702155590549, metrics={'train_runtime': 8856.819, 'train_samples_per_second': 26.276, 'train_steps_per_second': 1.094, 'total_flos': 5.06499773976576e+16, 'train_loss': 0.3022702155590549, 'epoch': 9.99})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kZ8mF9mqdyCt"},"outputs":[],"source":["!mv /content/log/events.out.tfevents.1707365662.dbb41ac8b909.854.0 /content/drive/MyDrive/CT208/2rd"]},{"cell_type":"markdown","metadata":{"id":"pE-wwbVD6bdV"},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zpp4qKpa6bdV"},"outputs":[],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/CT208/2rd/checkpoint-9690\")\n","model.to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"elapsed":338527,"status":"ok","timestamp":1707375352906,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"GS6fG4RH6bdV","outputId":"df5328e9-ea9e-4190-84c8-95595b268040"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-17-4a8b4e0b284a>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metrics = load_metric('rouge')\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5408efbccbe14d6d9bddb0a36d1afe17","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9a7afb39cca42c4885dddf5ef28a4c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/156 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"text/plain":["{'rouge1': AggregateScore(low=Score(precision=0.9834747456030071, recall=0.9819610463565717, fmeasure=0.9826422890804603), mid=Score(precision=0.984335839069195, recall=0.9828259745056115, fmeasure=0.9834553737075293), high=Score(precision=0.9851464778726258, recall=0.9836982404695586, fmeasure=0.984279538783495)),\n"," 'rouge2': AggregateScore(low=Score(precision=0.9716482581189224, recall=0.9700250787394225, fmeasure=0.9707623506365148), mid=Score(precision=0.9730215106721225, recall=0.9715156641903945, fmeasure=0.9721647710199142), high=Score(precision=0.9743620065939519, recall=0.9729230313365992, fmeasure=0.9735553828918491)),\n"," 'rougeL': AggregateScore(low=Score(precision=0.9824504386590022, recall=0.9808880918698047, fmeasure=0.981579063391171), mid=Score(precision=0.9834053482518403, recall=0.9818796565565557, fmeasure=0.9825250459119504), high=Score(precision=0.9843379333680138, recall=0.9827983958249998, fmeasure=0.9834433858242191)),\n"," 'rougeLsum': AggregateScore(low=Score(precision=0.9825066671447572, recall=0.9809453052902828, fmeasure=0.9816569165681428), mid=Score(precision=0.9834647564768748, recall=0.9819199548545556, fmeasure=0.9825770888165091), high=Score(precision=0.9844228080682523, recall=0.9828224368333616, fmeasure=0.9834842218420179))}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["metrics = load_metric('rouge')\n","\n","max_target_length = 300\n","dataloader = torch.utils.data.DataLoader(tokenized_test_set, collate_fn=data_collator, batch_size=32)\n","\n","predictions = []\n","references = []\n","for i, batch in enumerate(tqdm(dataloader)):\n","    outputs = model.generate(\n","        input_ids=batch['input_ids'].to('cuda'),\n","        max_length=max_target_length,\n","        attention_mask=batch['attention_mask'].to('cuda'),\n","    )\n","    with tokenizer.as_target_tokenizer():\n","        outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n","\n","        labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n","        actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n","    predictions.extend(outputs)\n","    references.extend(actuals)\n","    metrics.add_batch(predictions=outputs, references=actuals)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30239,"status":"ok","timestamp":1707375389398,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"e_yRARVD6bdV","outputId":"224294d0-8c47-47ca-c72a-c748b05aad1d"},"outputs":[{"data":{"text/plain":["[{'rouge1': 0.9834553737075293},\n"," {'rouge2': 0.9721647710199142},\n"," {'rougeL': 0.9825250459119504},\n"," {'rougeLsum': 0.9825770888165091}]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["[{k: v.mid.fmeasure} for k,v in metrics.compute(predictions=predictions, references=references).items()]"]},{"cell_type":"markdown","metadata":{"id":"Dcd9ApHp6bdV"},"source":["## Generate text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11863,"status":"ok","timestamp":1707377111747,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"690bdWBC6bdW","outputId":"4685457f-c190-4123-cb3a-cc0b9be3681d"},"outputs":[{"name":"stdout","output_type":"stream","text":["lam sao de giai quyet van de nay day?\n","Làm sao để giải quyết vấn đề này đây? \n"]}],"source":["sentence = input()\n","text =  sentence + \" </s>\"\n","encoding = tokenizer(text, return_tensors=\"pt\")\n","input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n","outputs = model.generate(\n","    input_ids=input_ids, attention_mask=attention_masks,\n","    max_length=300,\n","    early_stopping=True\n",")\n","for output in outputs:\n","    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","    print(line)"]},{"cell_type":"markdown","metadata":{"id":"g0nBQZB2XHtm"},"source":["# 4th"]},{"cell_type":"markdown","metadata":{"id":"oXMvlPjgXHtx"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cwIjhTCSXHtx"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/CT208/4th\",\n","    do_train=True,\n","    do_eval=True,\n","    num_train_epochs=6,\n","    learning_rate=1e-5,\n","    warmup_ratio=0.05,\n","    weight_decay=0.01,\n","    prediction_loss_only = True,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    logging_dir='/content/drive/MyDrive/CT208/4th',\n","    group_by_length=True,\n","    save_strategy=\"epoch\",\n","    save_total_limit=1,\n","    evaluation_strategy=\"epoch\",\n","    fp16=True,\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train_set,\n","    data_collator=data_collator,\n","    eval_dataset=tokenized_val_set\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vv3LDfCvVOaC"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":155},"id":"62J-1LzXXHtx","outputId":"71085060-988d-4287-fde3-994fbcd53563"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='25276' max='71304' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [25276/71304 1:57:14 < 3:33:31, 3.59 it/s, Epoch 2.13/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.078500</td>\n","      <td>0.072845</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.041900</td>\n","      <td>0.046855</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"aJ9Iwhv7XHtx"},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28389,"status":"ok","timestamp":1707706072205,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"rLFVJyb7XHty","outputId":"f64f4917-ed9f-40c8-ec77-be520547af47"},"outputs":[{"data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(36096, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/CT208/4th/checkpoint-23768\")\n","model.to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448},"executionInfo":{"elapsed":338527,"status":"ok","timestamp":1707375352906,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"RGwAL5PxXHty","outputId":"df5328e9-ea9e-4190-84c8-95595b268040"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-17-4a8b4e0b284a>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metrics = load_metric('rouge')\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5408efbccbe14d6d9bddb0a36d1afe17","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9a7afb39cca42c4885dddf5ef28a4c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/156 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"text/plain":["{'rouge1': AggregateScore(low=Score(precision=0.9834747456030071, recall=0.9819610463565717, fmeasure=0.9826422890804603), mid=Score(precision=0.984335839069195, recall=0.9828259745056115, fmeasure=0.9834553737075293), high=Score(precision=0.9851464778726258, recall=0.9836982404695586, fmeasure=0.984279538783495)),\n"," 'rouge2': AggregateScore(low=Score(precision=0.9716482581189224, recall=0.9700250787394225, fmeasure=0.9707623506365148), mid=Score(precision=0.9730215106721225, recall=0.9715156641903945, fmeasure=0.9721647710199142), high=Score(precision=0.9743620065939519, recall=0.9729230313365992, fmeasure=0.9735553828918491)),\n"," 'rougeL': AggregateScore(low=Score(precision=0.9824504386590022, recall=0.9808880918698047, fmeasure=0.981579063391171), mid=Score(precision=0.9834053482518403, recall=0.9818796565565557, fmeasure=0.9825250459119504), high=Score(precision=0.9843379333680138, recall=0.9827983958249998, fmeasure=0.9834433858242191)),\n"," 'rougeLsum': AggregateScore(low=Score(precision=0.9825066671447572, recall=0.9809453052902828, fmeasure=0.9816569165681428), mid=Score(precision=0.9834647564768748, recall=0.9819199548545556, fmeasure=0.9825770888165091), high=Score(precision=0.9844228080682523, recall=0.9828224368333616, fmeasure=0.9834842218420179))}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["metrics = load_metric('rouge')\n","\n","max_target_length = 300\n","dataloader = torch.utils.data.DataLoader(tokenized_test_set, collate_fn=data_collator, batch_size=32)\n","\n","predictions = []\n","references = []\n","for i, batch in enumerate(tqdm(dataloader)):\n","    outputs = model.generate(\n","        input_ids=batch['input_ids'].to('cuda'),\n","        max_length=max_target_length,\n","        attention_mask=batch['attention_mask'].to('cuda'),\n","    )\n","    with tokenizer.as_target_tokenizer():\n","        outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n","\n","        labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n","        actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n","    predictions.extend(outputs)\n","    references.extend(actuals)\n","    metrics.add_batch(predictions=outputs, references=actuals)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30239,"status":"ok","timestamp":1707375389398,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"SKECwIe6XHty","outputId":"224294d0-8c47-47ca-c72a-c748b05aad1d"},"outputs":[{"data":{"text/plain":["[{'rouge1': 0.9834553737075293},\n"," {'rouge2': 0.9721647710199142},\n"," {'rougeL': 0.9825250459119504},\n"," {'rougeLsum': 0.9825770888165091}]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["[{k: v.mid.fmeasure} for k,v in metrics.compute(predictions=predictions, references=references).items()]"]},{"cell_type":"markdown","metadata":{"id":"gNEFCU8YXHty"},"source":["## Generate text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3707,"status":"ok","timestamp":1707706369628,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"fS_cqWz1XHty","outputId":"23cade0a-d628-47c5-8e41-5db9cb209827"},"outputs":[{"name":"stdout","output_type":"stream","text":["Canh sat cho biet Kiptum la nguoi dieu khien chiec xe mat lai va lan banh khien ca hai tu vong tai cho Mot phat ngon vien duoc AFP dan loi noi them rang hanh khach thu ba la nu bi thuong va duoc dua den benh vien\n","Cảnh sát cho biết Kiptum là người điều khiển chiếc xe mất lái và lăn bánh khiến cả hai tử vong tại chỗ Một phát ngôn viên được AFP dẫn lời nói thêm rằng hành khách thứ ba là nữ bị thương và được đưa đến bệnh viện \n"]}],"source":["sentence = input()\n","text =  sentence + \" </s>\"\n","encoding = tokenizer(text, return_tensors=\"pt\")\n","input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n","outputs = model.generate(\n","    input_ids=input_ids, attention_mask=attention_masks,\n","    max_length=300,\n","    early_stopping=True\n",")\n","for output in outputs:\n","    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","    print(line)"]},{"cell_type":"markdown","metadata":{"id":"8e-Jo4VBVS0P"},"source":["# 5th"]},{"cell_type":"markdown","metadata":{"id":"7ZwwFiy8VS0X"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2444mGexVS0X"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n","\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/CT208/5th\",\n","    do_train=True,\n","    do_eval=True,\n","    num_train_epochs=3,\n","    learning_rate=1e-5,\n","    warmup_ratio=0.05,\n","    weight_decay=0.01,\n","    prediction_loss_only = True,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    logging_dir='/content/drive/MyDrive/CT208/5th',\n","    group_by_length=True,\n","    save_strategy=\"epoch\",\n","    save_total_limit=1,\n","    evaluation_strategy=\"epoch\",\n","    fp16=True,\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_train_set,\n","    data_collator=data_collator,\n","    eval_dataset=tokenized_val_set\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZ8Ybhv4VS0X"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":155},"id":"yj8IcBYaVS0X","outputId":"71085060-988d-4287-fde3-994fbcd53563"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='25276' max='71304' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [25276/71304 1:57:14 < 3:33:31, 3.59 it/s, Epoch 2.13/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.078500</td>\n","      <td>0.072845</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.041900</td>\n","      <td>0.046855</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"8I3jEHJUVS0X"},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28389,"status":"ok","timestamp":1707706072205,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"BCh-huQoVS0Y","outputId":"f64f4917-ed9f-40c8-ec77-be520547af47"},"outputs":[{"data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(36096, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/CT208/4th/checkpoint-23768\")\n","model.to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":448,"referenced_widgets":["5408efbccbe14d6d9bddb0a36d1afe17","8621a77b26604ca4946dd2dc011b81f5","1348cce0cdf4408f9180cfe2e9ea59aa","8043f20580964a33817054ccfdf11a80","897f1ee45e2a4707886949269eebf214","ac193365f23c49a58c5a2bb51b16d2e6","052740f71445445bb946441bbede7753","ce68b73f532b40baaba692c2de1b3fb9","0f243e9c0f474cac950fab4e8a6fc942","3bb5503df44d4516b241fd19fe1db352","fb28c9dcfdb54f2f8dc971ed003f9a49","a9a7afb39cca42c4885dddf5ef28a4c0","9d627c93ece24aae8598060d8d23e179","a6e1c4899cb744fc82b66f377ca780dc","b90faf92196f4121abee7d912a0461d1","99e21fa532ae48c381e020ff7f89ca54","6347e6a9f8194b5b8b2d1d76414a7400","c4ea0823817c41e9bf6364fcdc609696","4d8c4bf6bcbe4da88cbf8e2dda82014d","4d6db1cf960e456bb3b13b29fb0c53f6","2aff276fb6504482a8c7759058ee1d3f","4a19667d07c3422f8ee4799af3fd376c"]},"executionInfo":{"elapsed":338527,"status":"ok","timestamp":1707375352906,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"bgRT7MmpVS0Y","outputId":"df5328e9-ea9e-4190-84c8-95595b268040"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-17-4a8b4e0b284a>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metrics = load_metric('rouge')\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5408efbccbe14d6d9bddb0a36d1afe17","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9a7afb39cca42c4885dddf5ef28a4c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/156 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"text/plain":["{'rouge1': AggregateScore(low=Score(precision=0.9834747456030071, recall=0.9819610463565717, fmeasure=0.9826422890804603), mid=Score(precision=0.984335839069195, recall=0.9828259745056115, fmeasure=0.9834553737075293), high=Score(precision=0.9851464778726258, recall=0.9836982404695586, fmeasure=0.984279538783495)),\n"," 'rouge2': AggregateScore(low=Score(precision=0.9716482581189224, recall=0.9700250787394225, fmeasure=0.9707623506365148), mid=Score(precision=0.9730215106721225, recall=0.9715156641903945, fmeasure=0.9721647710199142), high=Score(precision=0.9743620065939519, recall=0.9729230313365992, fmeasure=0.9735553828918491)),\n"," 'rougeL': AggregateScore(low=Score(precision=0.9824504386590022, recall=0.9808880918698047, fmeasure=0.981579063391171), mid=Score(precision=0.9834053482518403, recall=0.9818796565565557, fmeasure=0.9825250459119504), high=Score(precision=0.9843379333680138, recall=0.9827983958249998, fmeasure=0.9834433858242191)),\n"," 'rougeLsum': AggregateScore(low=Score(precision=0.9825066671447572, recall=0.9809453052902828, fmeasure=0.9816569165681428), mid=Score(precision=0.9834647564768748, recall=0.9819199548545556, fmeasure=0.9825770888165091), high=Score(precision=0.9844228080682523, recall=0.9828224368333616, fmeasure=0.9834842218420179))}"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["metrics = load_metric('rouge')\n","\n","max_target_length = 300\n","dataloader = torch.utils.data.DataLoader(tokenized_test_set, collate_fn=data_collator, batch_size=32)\n","\n","predictions = []\n","references = []\n","for i, batch in enumerate(tqdm(dataloader)):\n","    outputs = model.generate(\n","        input_ids=batch['input_ids'].to('cuda'),\n","        max_length=max_target_length,\n","        attention_mask=batch['attention_mask'].to('cuda'),\n","    )\n","    with tokenizer.as_target_tokenizer():\n","        outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n","\n","        labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n","        actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n","    predictions.extend(outputs)\n","    references.extend(actuals)\n","    metrics.add_batch(predictions=outputs, references=actuals)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30239,"status":"ok","timestamp":1707375389398,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"sylG66aSVS0Y","outputId":"224294d0-8c47-47ca-c72a-c748b05aad1d"},"outputs":[{"data":{"text/plain":["[{'rouge1': 0.9834553737075293},\n"," {'rouge2': 0.9721647710199142},\n"," {'rougeL': 0.9825250459119504},\n"," {'rougeLsum': 0.9825770888165091}]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["[{k: v.mid.fmeasure} for k,v in metrics.compute(predictions=predictions, references=references).items()]"]},{"cell_type":"markdown","metadata":{"id":"WYB077I7VS0Y"},"source":["## Generate text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3707,"status":"ok","timestamp":1707706369628,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"8GrOWrPtVS0Y","outputId":"23cade0a-d628-47c5-8e41-5db9cb209827"},"outputs":[{"name":"stdout","output_type":"stream","text":["Canh sat cho biet Kiptum la nguoi dieu khien chiec xe mat lai va lan banh khien ca hai tu vong tai cho Mot phat ngon vien duoc AFP dan loi noi them rang hanh khach thu ba la nu bi thuong va duoc dua den benh vien\n","Cảnh sát cho biết Kiptum là người điều khiển chiếc xe mất lái và lăn bánh khiến cả hai tử vong tại chỗ Một phát ngôn viên được AFP dẫn lời nói thêm rằng hành khách thứ ba là nữ bị thương và được đưa đến bệnh viện \n"]}],"source":["sentence = input()\n","text =  sentence + \" </s>\"\n","encoding = tokenizer(text, return_tensors=\"pt\")\n","input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n","outputs = model.generate(\n","    input_ids=input_ids, attention_mask=attention_masks,\n","    max_length=300,\n","    early_stopping=True\n",")\n","for output in outputs:\n","    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","    print(line)"]}],"metadata":{"colab":{"collapsed_sections":["tcmYh1-n8vFr","1LYWuj6l9XYk","MY44BLZgXybu","t2ayW4xAX0x0","vakA7VPCX7O-","BZNsOK03DojH","GY37m9wgDojT","vEvJu1qxDojU","Qip-qrmeOu4s","SWptVibrOu42","_jzJR92p6bdJ","g0nBQZB2XHtm"],"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"052740f71445445bb946441bbede7753":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f243e9c0f474cac950fab4e8a6fc942":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1348cce0cdf4408f9180cfe2e9ea59aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce68b73f532b40baaba692c2de1b3fb9","max":2169,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f243e9c0f474cac950fab4e8a6fc942","value":2169}},"2aff276fb6504482a8c7759058ee1d3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bb5503df44d4516b241fd19fe1db352":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a19667d07c3422f8ee4799af3fd376c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d6db1cf960e456bb3b13b29fb0c53f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d8c4bf6bcbe4da88cbf8e2dda82014d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5408efbccbe14d6d9bddb0a36d1afe17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8621a77b26604ca4946dd2dc011b81f5","IPY_MODEL_1348cce0cdf4408f9180cfe2e9ea59aa","IPY_MODEL_8043f20580964a33817054ccfdf11a80"],"layout":"IPY_MODEL_897f1ee45e2a4707886949269eebf214"}},"6347e6a9f8194b5b8b2d1d76414a7400":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8043f20580964a33817054ccfdf11a80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bb5503df44d4516b241fd19fe1db352","placeholder":"​","style":"IPY_MODEL_fb28c9dcfdb54f2f8dc971ed003f9a49","value":" 5.65k/? [00:00&lt;00:00, 207kB/s]"}},"8621a77b26604ca4946dd2dc011b81f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac193365f23c49a58c5a2bb51b16d2e6","placeholder":"​","style":"IPY_MODEL_052740f71445445bb946441bbede7753","value":"Downloading builder script: "}},"897f1ee45e2a4707886949269eebf214":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99e21fa532ae48c381e020ff7f89ca54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d627c93ece24aae8598060d8d23e179":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6347e6a9f8194b5b8b2d1d76414a7400","placeholder":"​","style":"IPY_MODEL_c4ea0823817c41e9bf6364fcdc609696","value":"100%"}},"a6e1c4899cb744fc82b66f377ca780dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d8c4bf6bcbe4da88cbf8e2dda82014d","max":156,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d6db1cf960e456bb3b13b29fb0c53f6","value":156}},"a9a7afb39cca42c4885dddf5ef28a4c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d627c93ece24aae8598060d8d23e179","IPY_MODEL_a6e1c4899cb744fc82b66f377ca780dc","IPY_MODEL_b90faf92196f4121abee7d912a0461d1"],"layout":"IPY_MODEL_99e21fa532ae48c381e020ff7f89ca54"}},"ac193365f23c49a58c5a2bb51b16d2e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b90faf92196f4121abee7d912a0461d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2aff276fb6504482a8c7759058ee1d3f","placeholder":"​","style":"IPY_MODEL_4a19667d07c3422f8ee4799af3fd376c","value":" 156/156 [05:17&lt;00:00,  1.93s/it]"}},"c4ea0823817c41e9bf6364fcdc609696":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce68b73f532b40baaba692c2de1b3fb9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb28c9dcfdb54f2f8dc971ed003f9a49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23b36407decb4f3a8204b44763bf14a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d9134c5f8d04c0f859f2a9aee60c94b","IPY_MODEL_3a3c8d88cf5d4fc2a9802381b43194ca","IPY_MODEL_c30ab84b37ee4a1ba51140057bb07d75"],"layout":"IPY_MODEL_ac9ab03aaa224ea5bfa4f0c39bfdb5b0"}},"3d9134c5f8d04c0f859f2a9aee60c94b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30bbaa98aae643f6b9f0606fb7d3dfc3","placeholder":"​","style":"IPY_MODEL_d0964606bea24d6dbbd4f13f1ff6376c","value":"tokenizer_config.json: 100%"}},"3a3c8d88cf5d4fc2a9802381b43194ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a071e0575b624fb79318446d59272f7d","max":2197,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74a41d102c814b548c5e063719c97d61","value":2197}},"c30ab84b37ee4a1ba51140057bb07d75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33f9200a2e7a4639bfec0aa755a940fd","placeholder":"​","style":"IPY_MODEL_8636444807db42b48ecf47fa515810be","value":" 2.20k/2.20k [00:00&lt;00:00, 67.7kB/s]"}},"ac9ab03aaa224ea5bfa4f0c39bfdb5b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30bbaa98aae643f6b9f0606fb7d3dfc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0964606bea24d6dbbd4f13f1ff6376c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a071e0575b624fb79318446d59272f7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74a41d102c814b548c5e063719c97d61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33f9200a2e7a4639bfec0aa755a940fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8636444807db42b48ecf47fa515810be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4dd94c82d84421c8f1dfcef6670132b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e78489760804f33a7756bb15495f21d","IPY_MODEL_59055d0b2a944b5b9841c22729165ac2","IPY_MODEL_4a9c7019baa0445db29dc66d4c814846"],"layout":"IPY_MODEL_8237e0b20a524d72bf54b9ae98a5372f"}},"5e78489760804f33a7756bb15495f21d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c3a02f2f48042bd88b4cece05f82ead","placeholder":"​","style":"IPY_MODEL_1e63a97979e44b92b7cad63dc9196dcd","value":"spiece.model: 100%"}},"59055d0b2a944b5b9841c22729165ac2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_42c93bc1554e4df3b6c7aac7812dd7b0","max":820370,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4cbdd04057cf455da1a0c070b5a78c5d","value":820370}},"4a9c7019baa0445db29dc66d4c814846":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c008fff625ed45c6a00ab61560e71c9b","placeholder":"​","style":"IPY_MODEL_1f4c304bc9f949d6981c1622ce33cdde","value":" 820k/820k [00:00&lt;00:00, 12.9MB/s]"}},"8237e0b20a524d72bf54b9ae98a5372f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c3a02f2f48042bd88b4cece05f82ead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e63a97979e44b92b7cad63dc9196dcd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42c93bc1554e4df3b6c7aac7812dd7b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cbdd04057cf455da1a0c070b5a78c5d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c008fff625ed45c6a00ab61560e71c9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f4c304bc9f949d6981c1622ce33cdde":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6f15ce69744461fbf48ff7718583466":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_97802713e8864dc3bf92fef59376b259","IPY_MODEL_e2657f8d8e354ac180ada4d48eaec39c","IPY_MODEL_877f32eb8ea3440eb1b756ff05e1879d"],"layout":"IPY_MODEL_522daf0d3d1145ebaed1dc833bc9cebf"}},"97802713e8864dc3bf92fef59376b259":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_032c8b2aba674dd1b27b3f91cf9876cc","placeholder":"​","style":"IPY_MODEL_bf336e25d63e4bfc915a7929b74aabfb","value":"tokenizer.json: 100%"}},"e2657f8d8e354ac180ada4d48eaec39c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4afdea8e2e7d438d8409ed1368c4d6e1","max":2399296,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04a3e793d49c44cb8af2d1937db50787","value":2399296}},"877f32eb8ea3440eb1b756ff05e1879d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a11ceed26bad4fc293d828b10b8d622b","placeholder":"​","style":"IPY_MODEL_5fb2d81266f84e86bdaa4791983be8ca","value":" 2.40M/2.40M [00:00&lt;00:00, 12.3MB/s]"}},"522daf0d3d1145ebaed1dc833bc9cebf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"032c8b2aba674dd1b27b3f91cf9876cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf336e25d63e4bfc915a7929b74aabfb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4afdea8e2e7d438d8409ed1368c4d6e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04a3e793d49c44cb8af2d1937db50787":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a11ceed26bad4fc293d828b10b8d622b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fb2d81266f84e86bdaa4791983be8ca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9711f4fd0ab345c3993a47c1c9725842":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8905de6a24bc467da3d238097a8b48af","IPY_MODEL_c87de47fb08342e49c583d5c0d9b970f","IPY_MODEL_ad8d4bd685f34c17848e70311a90f784"],"layout":"IPY_MODEL_b6c4f36afa234d83b9ab45196d513144"}},"8905de6a24bc467da3d238097a8b48af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd9874f60840466b8dcbe0c35bf584e7","placeholder":"​","style":"IPY_MODEL_c40d7f0b323343199e3c01475803e4a4","value":"special_tokens_map.json: 100%"}},"c87de47fb08342e49c583d5c0d9b970f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_19bf55d6b492439095e54d2722f930a0","max":2117,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43136350163d4b17a7b998a3907e5839","value":2117}},"ad8d4bd685f34c17848e70311a90f784":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_203cfb274ca344e488d25e8b43d47e6a","placeholder":"​","style":"IPY_MODEL_f7d41dc84303451e852d9b1526b9a9c1","value":" 2.12k/2.12k [00:00&lt;00:00, 88.7kB/s]"}},"b6c4f36afa234d83b9ab45196d513144":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd9874f60840466b8dcbe0c35bf584e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c40d7f0b323343199e3c01475803e4a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19bf55d6b492439095e54d2722f930a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43136350163d4b17a7b998a3907e5839":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"203cfb274ca344e488d25e8b43d47e6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7d41dc84303451e852d9b1526b9a9c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2231b553a9b434cabce3a7e9d313bd0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ece6b37de2d0422a9fd7a6350b9ba162","IPY_MODEL_ec632f25cf0b4269a28fe8deb2e4bd56","IPY_MODEL_6e763c4681ea4035be18aba062433d75"],"layout":"IPY_MODEL_8fa9c6d30c684343b0593d908165b113"}},"ece6b37de2d0422a9fd7a6350b9ba162":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7c6dfdac5b64f088585782f4971059b","placeholder":"​","style":"IPY_MODEL_92610853e87a46b8832e779ea3cac671","value":"config.json: 100%"}},"ec632f25cf0b4269a28fe8deb2e4bd56":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2026774db6684c05ac75a71aa8ffc35b","max":702,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd3ac9c65b4e42a3afe26ca2d6a31f60","value":702}},"6e763c4681ea4035be18aba062433d75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_338c2a94269c452daa75906779a64869","placeholder":"​","style":"IPY_MODEL_f4690be6020c4e828ca3c2e22192ba09","value":" 702/702 [00:00&lt;00:00, 21.1kB/s]"}},"8fa9c6d30c684343b0593d908165b113":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7c6dfdac5b64f088585782f4971059b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92610853e87a46b8832e779ea3cac671":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2026774db6684c05ac75a71aa8ffc35b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd3ac9c65b4e42a3afe26ca2d6a31f60":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"338c2a94269c452daa75906779a64869":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4690be6020c4e828ca3c2e22192ba09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b57d754d09d6484ba1a1f0d36bcce051":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f4a6dbc33cc4277abf78338061e3f17","IPY_MODEL_38abb0b97d564d139169acfa9b196cb9","IPY_MODEL_8f2b971cb30d451ea960f5921044d37a"],"layout":"IPY_MODEL_43fe76e200b24a7da318dd450a78b473"}},"1f4a6dbc33cc4277abf78338061e3f17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d23961bc83e4c86843e3809077cb6ea","placeholder":"​","style":"IPY_MODEL_f3e02b3ce3b84a55953e8d5c610aba4f","value":"pytorch_model.bin: 100%"}},"38abb0b97d564d139169acfa9b196cb9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3b5f4e32e964bc9b8a3977cb60c1b35","max":903886847,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b50ad3562414b468127f31424cdbf70","value":903886847}},"8f2b971cb30d451ea960f5921044d37a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e1504db86cd403a8fd5d7713ce7a9a4","placeholder":"​","style":"IPY_MODEL_9baca84aba88425e972f863b6cbb6696","value":" 904M/904M [00:10&lt;00:00, 77.9MB/s]"}},"43fe76e200b24a7da318dd450a78b473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d23961bc83e4c86843e3809077cb6ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f3e02b3ce3b84a55953e8d5c610aba4f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3b5f4e32e964bc9b8a3977cb60c1b35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b50ad3562414b468127f31424cdbf70":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e1504db86cd403a8fd5d7713ce7a9a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9baca84aba88425e972f863b6cbb6696":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}