{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["tcmYh1-n8vFr","1LYWuj6l9XYk","MY44BLZgXybu","t2ayW4xAX0x0","vakA7VPCX7O-","BZNsOK03DojH","GY37m9wgDojT","vEvJu1qxDojU","Qip-qrmeOu4s","SWptVibrOu42","_jzJR92p6bdJ","g0nBQZB2XHtm"],"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7636241,"sourceType":"datasetVersion","datasetId":4449966},{"sourceId":7649293,"sourceType":"datasetVersion","datasetId":4459089}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"032c8b2aba674dd1b27b3f91cf9876cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04a3e793d49c44cb8af2d1937db50787":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"052740f71445445bb946441bbede7753":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f243e9c0f474cac950fab4e8a6fc942":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1348cce0cdf4408f9180cfe2e9ea59aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce68b73f532b40baaba692c2de1b3fb9","max":2169,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f243e9c0f474cac950fab4e8a6fc942","value":2169}},"19bf55d6b492439095e54d2722f930a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e63a97979e44b92b7cad63dc9196dcd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f4a6dbc33cc4277abf78338061e3f17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d23961bc83e4c86843e3809077cb6ea","placeholder":"​","style":"IPY_MODEL_f3e02b3ce3b84a55953e8d5c610aba4f","value":"pytorch_model.bin: 100%"}},"1f4c304bc9f949d6981c1622ce33cdde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2026774db6684c05ac75a71aa8ffc35b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"203cfb274ca344e488d25e8b43d47e6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23b36407decb4f3a8204b44763bf14a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d9134c5f8d04c0f859f2a9aee60c94b","IPY_MODEL_3a3c8d88cf5d4fc2a9802381b43194ca","IPY_MODEL_c30ab84b37ee4a1ba51140057bb07d75"],"layout":"IPY_MODEL_ac9ab03aaa224ea5bfa4f0c39bfdb5b0"}},"2aff276fb6504482a8c7759058ee1d3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d23961bc83e4c86843e3809077cb6ea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30bbaa98aae643f6b9f0606fb7d3dfc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"338c2a94269c452daa75906779a64869":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33f9200a2e7a4639bfec0aa755a940fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38abb0b97d564d139169acfa9b196cb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3b5f4e32e964bc9b8a3977cb60c1b35","max":903886847,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b50ad3562414b468127f31424cdbf70","value":903886847}},"3a3c8d88cf5d4fc2a9802381b43194ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a071e0575b624fb79318446d59272f7d","max":2197,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74a41d102c814b548c5e063719c97d61","value":2197}},"3bb5503df44d4516b241fd19fe1db352":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d9134c5f8d04c0f859f2a9aee60c94b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_30bbaa98aae643f6b9f0606fb7d3dfc3","placeholder":"​","style":"IPY_MODEL_d0964606bea24d6dbbd4f13f1ff6376c","value":"tokenizer_config.json: 100%"}},"3e1504db86cd403a8fd5d7713ce7a9a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42c93bc1554e4df3b6c7aac7812dd7b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43136350163d4b17a7b998a3907e5839":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43fe76e200b24a7da318dd450a78b473":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a19667d07c3422f8ee4799af3fd376c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a9c7019baa0445db29dc66d4c814846":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c008fff625ed45c6a00ab61560e71c9b","placeholder":"​","style":"IPY_MODEL_1f4c304bc9f949d6981c1622ce33cdde","value":" 820k/820k [00:00&lt;00:00, 12.9MB/s]"}},"4afdea8e2e7d438d8409ed1368c4d6e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cbdd04057cf455da1a0c070b5a78c5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d6db1cf960e456bb3b13b29fb0c53f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4d8c4bf6bcbe4da88cbf8e2dda82014d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"522daf0d3d1145ebaed1dc833bc9cebf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5408efbccbe14d6d9bddb0a36d1afe17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8621a77b26604ca4946dd2dc011b81f5","IPY_MODEL_1348cce0cdf4408f9180cfe2e9ea59aa","IPY_MODEL_8043f20580964a33817054ccfdf11a80"],"layout":"IPY_MODEL_897f1ee45e2a4707886949269eebf214"}},"59055d0b2a944b5b9841c22729165ac2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_42c93bc1554e4df3b6c7aac7812dd7b0","max":820370,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4cbdd04057cf455da1a0c070b5a78c5d","value":820370}},"5e78489760804f33a7756bb15495f21d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c3a02f2f48042bd88b4cece05f82ead","placeholder":"​","style":"IPY_MODEL_1e63a97979e44b92b7cad63dc9196dcd","value":"spiece.model: 100%"}},"5fb2d81266f84e86bdaa4791983be8ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6347e6a9f8194b5b8b2d1d76414a7400":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b50ad3562414b468127f31424cdbf70":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e763c4681ea4035be18aba062433d75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_338c2a94269c452daa75906779a64869","placeholder":"​","style":"IPY_MODEL_f4690be6020c4e828ca3c2e22192ba09","value":" 702/702 [00:00&lt;00:00, 21.1kB/s]"}},"74a41d102c814b548c5e063719c97d61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c3a02f2f48042bd88b4cece05f82ead":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8043f20580964a33817054ccfdf11a80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bb5503df44d4516b241fd19fe1db352","placeholder":"​","style":"IPY_MODEL_fb28c9dcfdb54f2f8dc971ed003f9a49","value":" 5.65k/? [00:00&lt;00:00, 207kB/s]"}},"8237e0b20a524d72bf54b9ae98a5372f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8621a77b26604ca4946dd2dc011b81f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac193365f23c49a58c5a2bb51b16d2e6","placeholder":"​","style":"IPY_MODEL_052740f71445445bb946441bbede7753","value":"Downloading builder script: "}},"8636444807db42b48ecf47fa515810be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"877f32eb8ea3440eb1b756ff05e1879d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a11ceed26bad4fc293d828b10b8d622b","placeholder":"​","style":"IPY_MODEL_5fb2d81266f84e86bdaa4791983be8ca","value":" 2.40M/2.40M [00:00&lt;00:00, 12.3MB/s]"}},"8905de6a24bc467da3d238097a8b48af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd9874f60840466b8dcbe0c35bf584e7","placeholder":"​","style":"IPY_MODEL_c40d7f0b323343199e3c01475803e4a4","value":"special_tokens_map.json: 100%"}},"897f1ee45e2a4707886949269eebf214":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f2b971cb30d451ea960f5921044d37a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e1504db86cd403a8fd5d7713ce7a9a4","placeholder":"​","style":"IPY_MODEL_9baca84aba88425e972f863b6cbb6696","value":" 904M/904M [00:10&lt;00:00, 77.9MB/s]"}},"8fa9c6d30c684343b0593d908165b113":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92610853e87a46b8832e779ea3cac671":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9711f4fd0ab345c3993a47c1c9725842":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8905de6a24bc467da3d238097a8b48af","IPY_MODEL_c87de47fb08342e49c583d5c0d9b970f","IPY_MODEL_ad8d4bd685f34c17848e70311a90f784"],"layout":"IPY_MODEL_b6c4f36afa234d83b9ab45196d513144"}},"97802713e8864dc3bf92fef59376b259":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_032c8b2aba674dd1b27b3f91cf9876cc","placeholder":"​","style":"IPY_MODEL_bf336e25d63e4bfc915a7929b74aabfb","value":"tokenizer.json: 100%"}},"99e21fa532ae48c381e020ff7f89ca54":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9baca84aba88425e972f863b6cbb6696":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9d627c93ece24aae8598060d8d23e179":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6347e6a9f8194b5b8b2d1d76414a7400","placeholder":"​","style":"IPY_MODEL_c4ea0823817c41e9bf6364fcdc609696","value":"100%"}},"a071e0575b624fb79318446d59272f7d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a11ceed26bad4fc293d828b10b8d622b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6e1c4899cb744fc82b66f377ca780dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d8c4bf6bcbe4da88cbf8e2dda82014d","max":156,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d6db1cf960e456bb3b13b29fb0c53f6","value":156}},"a7c6dfdac5b64f088585782f4971059b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9a7afb39cca42c4885dddf5ef28a4c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9d627c93ece24aae8598060d8d23e179","IPY_MODEL_a6e1c4899cb744fc82b66f377ca780dc","IPY_MODEL_b90faf92196f4121abee7d912a0461d1"],"layout":"IPY_MODEL_99e21fa532ae48c381e020ff7f89ca54"}},"ac193365f23c49a58c5a2bb51b16d2e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac9ab03aaa224ea5bfa4f0c39bfdb5b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad8d4bd685f34c17848e70311a90f784":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_203cfb274ca344e488d25e8b43d47e6a","placeholder":"​","style":"IPY_MODEL_f7d41dc84303451e852d9b1526b9a9c1","value":" 2.12k/2.12k [00:00&lt;00:00, 88.7kB/s]"}},"b3b5f4e32e964bc9b8a3977cb60c1b35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b57d754d09d6484ba1a1f0d36bcce051":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f4a6dbc33cc4277abf78338061e3f17","IPY_MODEL_38abb0b97d564d139169acfa9b196cb9","IPY_MODEL_8f2b971cb30d451ea960f5921044d37a"],"layout":"IPY_MODEL_43fe76e200b24a7da318dd450a78b473"}},"b6c4f36afa234d83b9ab45196d513144":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b90faf92196f4121abee7d912a0461d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2aff276fb6504482a8c7759058ee1d3f","placeholder":"​","style":"IPY_MODEL_4a19667d07c3422f8ee4799af3fd376c","value":" 156/156 [05:17&lt;00:00,  1.93s/it]"}},"bd9874f60840466b8dcbe0c35bf584e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf336e25d63e4bfc915a7929b74aabfb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c008fff625ed45c6a00ab61560e71c9b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2231b553a9b434cabce3a7e9d313bd0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ece6b37de2d0422a9fd7a6350b9ba162","IPY_MODEL_ec632f25cf0b4269a28fe8deb2e4bd56","IPY_MODEL_6e763c4681ea4035be18aba062433d75"],"layout":"IPY_MODEL_8fa9c6d30c684343b0593d908165b113"}},"c30ab84b37ee4a1ba51140057bb07d75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33f9200a2e7a4639bfec0aa755a940fd","placeholder":"​","style":"IPY_MODEL_8636444807db42b48ecf47fa515810be","value":" 2.20k/2.20k [00:00&lt;00:00, 67.7kB/s]"}},"c40d7f0b323343199e3c01475803e4a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4ea0823817c41e9bf6364fcdc609696":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c87de47fb08342e49c583d5c0d9b970f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_19bf55d6b492439095e54d2722f930a0","max":2117,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43136350163d4b17a7b998a3907e5839","value":2117}},"ce68b73f532b40baaba692c2de1b3fb9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d0964606bea24d6dbbd4f13f1ff6376c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6f15ce69744461fbf48ff7718583466":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_97802713e8864dc3bf92fef59376b259","IPY_MODEL_e2657f8d8e354ac180ada4d48eaec39c","IPY_MODEL_877f32eb8ea3440eb1b756ff05e1879d"],"layout":"IPY_MODEL_522daf0d3d1145ebaed1dc833bc9cebf"}},"e2657f8d8e354ac180ada4d48eaec39c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4afdea8e2e7d438d8409ed1368c4d6e1","max":2399296,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04a3e793d49c44cb8af2d1937db50787","value":2399296}},"ec632f25cf0b4269a28fe8deb2e4bd56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2026774db6684c05ac75a71aa8ffc35b","max":702,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd3ac9c65b4e42a3afe26ca2d6a31f60","value":702}},"ece6b37de2d0422a9fd7a6350b9ba162":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7c6dfdac5b64f088585782f4971059b","placeholder":"​","style":"IPY_MODEL_92610853e87a46b8832e779ea3cac671","value":"config.json: 100%"}},"f3e02b3ce3b84a55953e8d5c610aba4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4690be6020c4e828ca3c2e22192ba09":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4dd94c82d84421c8f1dfcef6670132b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e78489760804f33a7756bb15495f21d","IPY_MODEL_59055d0b2a944b5b9841c22729165ac2","IPY_MODEL_4a9c7019baa0445db29dc66d4c814846"],"layout":"IPY_MODEL_8237e0b20a524d72bf54b9ae98a5372f"}},"f7d41dc84303451e852d9b1526b9a9c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb28c9dcfdb54f2f8dc971ed003f9a49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd3ac9c65b4e42a3afe26ca2d6a31f60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{"id":"tcmYh1-n8vFr"}},{"cell_type":"code","source":"%%capture\n!pip install datasets evaluate transformers\n!pip install rouge_score\n!pip install accelerate","metadata":{"executionInfo":{"elapsed":40914,"status":"ok","timestamp":1707740185468,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"eE1hHegMzV2Y","execution":{"iopub.status.busy":"2024-02-18T23:56:30.262949Z","iopub.execute_input":"2024-02-18T23:56:30.263431Z","iopub.status.idle":"2024-02-18T23:57:13.685502Z","shell.execute_reply.started":"2024-02-18T23:56:30.263392Z","shell.execute_reply":"2024-02-18T23:57:13.684403Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments, Seq2SeqTrainingArguments\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import DataLoader\nimport pandas as pd\nfrom datasets import load_metric\nimport torch\nimport numpy as np","metadata":{"executionInfo":{"elapsed":18668,"status":"ok","timestamp":1707740204129,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"0k0a9jYh1N8h","execution":{"iopub.status.busy":"2024-02-18T23:57:28.640451Z","iopub.execute_input":"2024-02-18T23:57:28.640810Z","iopub.status.idle":"2024-02-18T23:57:56.768911Z","shell.execute_reply.started":"2024-02-18T23:57:28.640782Z","shell.execute_reply":"2024-02-18T23:57:56.768019Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-02-18 23:57:42.925350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-18 23:57:42.925466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-18 23:57:43.204259: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/vit5-base\")\nmodel.to('cuda')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["23b36407decb4f3a8204b44763bf14a7","3d9134c5f8d04c0f859f2a9aee60c94b","3a3c8d88cf5d4fc2a9802381b43194ca","c30ab84b37ee4a1ba51140057bb07d75","ac9ab03aaa224ea5bfa4f0c39bfdb5b0","30bbaa98aae643f6b9f0606fb7d3dfc3","d0964606bea24d6dbbd4f13f1ff6376c","a071e0575b624fb79318446d59272f7d","74a41d102c814b548c5e063719c97d61","33f9200a2e7a4639bfec0aa755a940fd","8636444807db42b48ecf47fa515810be","f4dd94c82d84421c8f1dfcef6670132b","5e78489760804f33a7756bb15495f21d","59055d0b2a944b5b9841c22729165ac2","4a9c7019baa0445db29dc66d4c814846","8237e0b20a524d72bf54b9ae98a5372f","7c3a02f2f48042bd88b4cece05f82ead","1e63a97979e44b92b7cad63dc9196dcd","42c93bc1554e4df3b6c7aac7812dd7b0","4cbdd04057cf455da1a0c070b5a78c5d","c008fff625ed45c6a00ab61560e71c9b","1f4c304bc9f949d6981c1622ce33cdde","d6f15ce69744461fbf48ff7718583466","97802713e8864dc3bf92fef59376b259","e2657f8d8e354ac180ada4d48eaec39c","877f32eb8ea3440eb1b756ff05e1879d","522daf0d3d1145ebaed1dc833bc9cebf","032c8b2aba674dd1b27b3f91cf9876cc","bf336e25d63e4bfc915a7929b74aabfb","4afdea8e2e7d438d8409ed1368c4d6e1","04a3e793d49c44cb8af2d1937db50787","a11ceed26bad4fc293d828b10b8d622b","5fb2d81266f84e86bdaa4791983be8ca","9711f4fd0ab345c3993a47c1c9725842","8905de6a24bc467da3d238097a8b48af","c87de47fb08342e49c583d5c0d9b970f","ad8d4bd685f34c17848e70311a90f784","b6c4f36afa234d83b9ab45196d513144","bd9874f60840466b8dcbe0c35bf584e7","c40d7f0b323343199e3c01475803e4a4","19bf55d6b492439095e54d2722f930a0","43136350163d4b17a7b998a3907e5839","203cfb274ca344e488d25e8b43d47e6a","f7d41dc84303451e852d9b1526b9a9c1","c2231b553a9b434cabce3a7e9d313bd0","ece6b37de2d0422a9fd7a6350b9ba162","ec632f25cf0b4269a28fe8deb2e4bd56","6e763c4681ea4035be18aba062433d75","8fa9c6d30c684343b0593d908165b113","a7c6dfdac5b64f088585782f4971059b","92610853e87a46b8832e779ea3cac671","2026774db6684c05ac75a71aa8ffc35b","fd3ac9c65b4e42a3afe26ca2d6a31f60","338c2a94269c452daa75906779a64869","f4690be6020c4e828ca3c2e22192ba09","b57d754d09d6484ba1a1f0d36bcce051","1f4a6dbc33cc4277abf78338061e3f17","38abb0b97d564d139169acfa9b196cb9","8f2b971cb30d451ea960f5921044d37a","43fe76e200b24a7da318dd450a78b473","2d23961bc83e4c86843e3809077cb6ea","f3e02b3ce3b84a55953e8d5c610aba4f","b3b5f4e32e964bc9b8a3977cb60c1b35","6b50ad3562414b468127f31424cdbf70","3e1504db86cd403a8fd5d7713ce7a9a4","9baca84aba88425e972f863b6cbb6696"]},"executionInfo":{"elapsed":22936,"status":"ok","timestamp":1707740227057,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"FSflnvY21VHZ","outputId":"92489cc5-8bc9-47f5-d494-c4cdea925674","execution":{"iopub.status.busy":"2024-02-18T23:58:27.300482Z","iopub.execute_input":"2024-02-18T23:58:27.301546Z","iopub.status.idle":"2024-02-18T23:58:42.251727Z","shell.execute_reply.started":"2024-02-18T23:58:27.301511Z","shell.execute_reply":"2024-02-18T23:58:42.250755Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1721de8182d4df8a2b36ac2e4141d1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/820k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7d1fa8d7b464eb49c3064df40f7108b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.40M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee9aa4493b90470d95064810c5a8721d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d2bea5b170746c195322f0e5db4d2df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3ca1f30d98a4668b90950d99b63b3e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/904M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa949468ba4c4d31ac905adf23314d67"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(36096, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(36096, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(36096, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing data","metadata":{"id":"8vNJeGsb84qd"}},{"cell_type":"code","source":"def preprocess_function(examples):\n    model_inputs = tokenizer(\n        examples[\"inputs\"], max_length=300, truncation=True, padding=True\n    )\n\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples[\"labels\"], max_length=300, truncation=True, padding=True\n        )\n    model_inputs['labels'] = labels['input_ids']\n    model_inputs['input_ids'] = model_inputs['input_ids']\n    return model_inputs","metadata":{"executionInfo":{"elapsed":373,"status":"ok","timestamp":1707740624480,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"mZc5goJX4ozS","execution":{"iopub.status.busy":"2024-02-18T23:58:47.879063Z","iopub.execute_input":"2024-02-18T23:58:47.879418Z","iopub.status.idle":"2024-02-18T23:58:47.885759Z","shell.execute_reply.started":"2024-02-18T23:58:47.879390Z","shell.execute_reply":"2024-02-18T23:58:47.884612Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_set = pd.read_csv(\"/kaggle/input/sport-vmese-sentences/train_set.csv\").astype(\"str\")\nval_set = pd.read_csv(\"/kaggle/input/sport-vmese-sentences/val_set.csv\").astype(\"str\")\ntest_set = pd.read_csv(\"/kaggle/input/sport-vmese-sentences/test_set.csv\").astype(\"str\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"elapsed":7,"status":"error","timestamp":1707740625029,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"w4g_B7m6CoLn","outputId":"78d600be-f05e-4b30-dd1e-2561b1e64bf8","execution":{"iopub.status.busy":"2024-02-18T23:58:51.823295Z","iopub.execute_input":"2024-02-18T23:58:51.823816Z","iopub.status.idle":"2024-02-18T23:58:52.914442Z","shell.execute_reply.started":"2024-02-18T23:58:51.823784Z","shell.execute_reply":"2024-02-18T23:58:52.913332Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def tokenize(data):\n    input_lines = data.iloc[:, 0].to_numpy()\n    label_lines = data.iloc[:, 1].to_numpy()\n    dict_obj = {'inputs': input_lines, 'labels': label_lines}\n    dataset = Dataset.from_dict(dict_obj)\n    tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=10)\n\n    return tokenized_datasets","metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1707740625030,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"mbwORjFT9wbt","execution":{"iopub.status.busy":"2024-02-18T23:58:55.787152Z","iopub.execute_input":"2024-02-18T23:58:55.787535Z","iopub.status.idle":"2024-02-18T23:58:55.794139Z","shell.execute_reply.started":"2024-02-18T23:58:55.787505Z","shell.execute_reply":"2024-02-18T23:58:55.792915Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenized_train_set = tokenize(train_set)","metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1707740625030,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"QQujZ_iJ-Rpd","execution":{"iopub.status.busy":"2024-02-18T23:58:58.651532Z","iopub.execute_input":"2024-02-18T23:58:58.652645Z","iopub.status.idle":"2024-02-18T23:59:16.887421Z","shell.execute_reply.started":"2024-02-18T23:58:58.652604Z","shell.execute_reply":"2024-02-18T23:59:16.886265Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"           ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1b18f90f801482f9401cbca9d9f8722"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0705ae2ec0cd4095ae5d4b7bd7bca005"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7832fb2b718b44dfa6c684c435ba03a6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e3707e8bbce42aab464c00706a24f55"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"660f053a6c1c4cf8bcd16159a0800fc8"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69941485db9e4022accaf96efba4a1e0"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27061c710df84cd7bfe579892fdefa61"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7d6c38d880443188c022b1dfa1cea6e"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#8:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b4744c5e968471d89ab1ba964997de6"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#9:   0%|          | 0/10 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a409a9bf775149c29c587425c1f6dcbd"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_val_set = tokenize(val_set)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T23:59:20.659169Z","iopub.execute_input":"2024-02-18T23:59:20.660139Z","iopub.status.idle":"2024-02-18T23:59:21.861629Z","shell.execute_reply.started":"2024-02-18T23:59:20.660102Z","shell.execute_reply":"2024-02-18T23:59:21.860408Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"              ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"826a57336bd14984bb8eceeca6eb6cb9"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f030bb8dee90431388559db174d764e1"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8604ba57e8654314be5b6ec988d05ba3"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2938ebb1d2cb4b72bf63ee7dfd738ed9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89943fd398064feab625753211857ec1"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3261d16b6d384878926b37af539300ca"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6a5da6054af43b49b2114e0828dfd1a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d140f5da365f4e688c50f1f975ef2681"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#8:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e1bbde39d2241cea002f098c6df00f3"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#9:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"782d8ae8fa1d4cacaeb4b404102bb915"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_test_set = tokenize(test_set)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T23:59:25.098666Z","iopub.execute_input":"2024-02-18T23:59:25.099129Z","iopub.status.idle":"2024-02-18T23:59:26.245711Z","shell.execute_reply.started":"2024-02-18T23:59:25.099088Z","shell.execute_reply":"2024-02-18T23:59:26.244713Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"              ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb6f3c24ba19494aaf7b243f70be6b40"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1a28bb582da4eb49e53452c2cdc6ff4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"733bf623b23d434e93de277d550b30ea"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  ","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"482467fcd436484ca233ae4eb50f5b36"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc5c1d8f1cc14604be7dcb5a9c2964bb"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bedb0aa0eaea47a9979ee958800bfd06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57095609c0e141b8b507a4195805b5d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b475c0357b6547edbe6001ac657e51d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#8:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8ab0f81dad44d458998ae4ec261dffd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#9:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8685c45925a4b75b45c74fa64bae7f1"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(tokenized_train_set))\nprint(len(tokenized_val_set))\nprint(len(tokenized_test_set))","metadata":{"executionInfo":{"elapsed":1285,"status":"aborted","timestamp":1707740625031,"user":{"displayName":"Huynh Duy Khoi B2007190","userId":"00234977391478863678"},"user_tz":-420},"id":"gct1eihfDWyj","execution":{"iopub.status.busy":"2024-02-18T23:59:29.337574Z","iopub.execute_input":"2024-02-18T23:59:29.338353Z","iopub.status.idle":"2024-02-18T23:59:29.343729Z","shell.execute_reply.started":"2024-02-18T23:59:29.338317Z","shell.execute_reply":"2024-02-18T23:59:29.342695Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"92729\n2144\n1243\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 8th","metadata":{}},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"/kaggle/working/1st\",\n    do_train=True,\n    do_eval=True,\n    num_train_epochs=2,\n    learning_rate=1e-4,\n    warmup_ratio=0.05,\n    weight_decay=0.01,\n    prediction_loss_only=True,\n    per_device_train_batch_size=9,\n    per_device_eval_batch_size=9,\n    logging_dir='/kaggle/working/1st',\n    group_by_length=True,\n    save_strategy=\"steps\",\n    save_steps=500,\n    save_total_limit=1,\n    evaluation_strategy=\"steps\",\n    eval_steps=500,\n    fp16=True,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train_set,\n    data_collator=data_collator,\n    eval_dataset=tokenized_val_set\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-18T23:59:38.430810Z","iopub.execute_input":"2024-02-18T23:59:38.431752Z","iopub.status.idle":"2024-02-18T23:59:40.062953Z","shell.execute_reply.started":"2024-02-18T23:59:38.431719Z","shell.execute_reply":"2024-02-18T23:59:40.061974Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"acc398b6c572515cdbf0044bc49909a609a7ba19\")","metadata":{"execution":{"iopub.status.busy":"2024-02-18T23:59:45.638963Z","iopub.execute_input":"2024-02-18T23:59:45.639631Z","iopub.status.idle":"2024-02-18T23:59:47.897159Z","shell.execute_reply.started":"2024-02-18T23:59:45.639596Z","shell.execute_reply":"2024-02-18T23:59:47.896208Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-18T23:59:51.566994Z","iopub.execute_input":"2024-02-18T23:59:51.568369Z","iopub.status.idle":"2024-02-19T03:41:30.659532Z","shell.execute_reply.started":"2024-02-18T23:59:51.568331Z","shell.execute_reply":"2024-02-19T03:41:30.657641Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhuynhduykhoi619\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.3 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240219_000034-jnrjpqxz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/huynhduykhoi619/huggingface/runs/jnrjpqxz' target=\"_blank\">dancing-rat-15</a></strong> to <a href='https://wandb.ai/huynhduykhoi619/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/huynhduykhoi619/huggingface' target=\"_blank\">https://wandb.ai/huynhduykhoi619/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/huynhduykhoi619/huggingface/runs/jnrjpqxz' target=\"_blank\">https://wandb.ai/huynhduykhoi619/huggingface/runs/jnrjpqxz</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10119' max='10304' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [10119/10304 3:40:16 < 04:01, 0.77 it/s, Epoch 1.96/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.566200</td>\n      <td>0.078689</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.057500</td>\n      <td>0.039071</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.036600</td>\n      <td>0.025304</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.028600</td>\n      <td>0.019229</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.023800</td>\n      <td>0.018134</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.020900</td>\n      <td>0.014383</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.018400</td>\n      <td>0.012664</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.016300</td>\n      <td>0.011948</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.015000</td>\n      <td>0.011921</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.014100</td>\n      <td>0.011953</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.010500</td>\n      <td>0.011176</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.008900</td>\n      <td>0.010821</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.008800</td>\n      <td>0.009594</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.008200</td>\n      <td>0.009447</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.007600</td>\n      <td>0.008631</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>0.007700</td>\n      <td>0.008169</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>0.007200</td>\n      <td>0.008655</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>0.006600</td>\n      <td>0.008586</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>0.006300</td>\n      <td>0.007338</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.006100</td>\n      <td>0.006867</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1874\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1878\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"!zip -r 1st.zip /kaggle/working/1st","metadata":{"execution":{"iopub.status.busy":"2024-02-19T03:41:45.310006Z","iopub.execute_input":"2024-02-19T03:41:45.310412Z","iopub.status.idle":"2024-02-19T03:44:11.594907Z","shell.execute_reply.started":"2024-02-19T03:41:45.310379Z","shell.execute_reply":"2024-02-19T03:44:11.593604Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/1st/ (stored 0%)\n  adding: kaggle/working/1st/checkpoint-10000/ (stored 0%)\n  adding: kaggle/working/1st/checkpoint-10000/model.safetensors (deflated 7%)\n  adding: kaggle/working/1st/checkpoint-10000/config.json (deflated 47%)\n  adding: kaggle/working/1st/checkpoint-10000/rng_state.pth (deflated 25%)\n  adding: kaggle/working/1st/checkpoint-10000/trainer_state.json (deflated 80%)\n  adding: kaggle/working/1st/checkpoint-10000/training_args.bin (deflated 51%)\n  adding: kaggle/working/1st/checkpoint-10000/optimizer.pt (deflated 9%)\n  adding: kaggle/working/1st/checkpoint-10000/generation_config.json (deflated 29%)\n  adding: kaggle/working/1st/checkpoint-10000/scheduler.pt (deflated 55%)\n  adding: kaggle/working/1st/events.out.tfevents.1708300834.0def845902dd.35.0 (deflated 65%)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/1st/checkpoint-10000\")\nmodel.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-02-19T03:44:37.028190Z","iopub.execute_input":"2024-02-19T03:44:37.028614Z","iopub.status.idle":"2024-02-19T03:44:38.474578Z","shell.execute_reply.started":"2024-02-19T03:44:37.028579Z","shell.execute_reply":"2024-02-19T03:44:38.473270Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(36096, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(36096, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(36096, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"metrics = load_metric('rouge')\n\nmax_target_length = 300\ndataloader = torch.utils.data.DataLoader(tokenized_test_set, collate_fn=data_collator, batch_size=32)\n\npredictions = []\nreferences = []\nfor i, batch in enumerate(tqdm(dataloader)):\n    outputs = model.generate(\n        input_ids=batch['input_ids'].to('cuda'),\n        max_length=max_target_length,\n        attention_mask=batch['attention_mask'].to('cuda'),\n    )\n    with tokenizer.as_target_tokenizer():\n        outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n\n        labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n        actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n    predictions.extend(outputs)\n    references.extend(actuals)\n    metrics.add_batch(predictions=outputs, references=actuals)\n    \n[{k: v.mid.fmeasure} for k,v in metrics.compute(predictions=predictions, references=references).items()]","metadata":{"execution":{"iopub.status.busy":"2024-02-19T03:44:50.285417Z","iopub.execute_input":"2024-02-19T03:44:50.286395Z","iopub.status.idle":"2024-02-19T03:45:54.280752Z","shell.execute_reply.started":"2024-02-19T03:44:50.286361Z","shell.execute_reply":"2024-02-19T03:45:54.279630Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b1515c6758473c902c399566809057"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/39 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da2e356df9d4490cbb33fdbe94295254"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"[{'rouge1': 0.9963257980977519},\n {'rouge2': 0.9937234430999218},\n {'rougeL': 0.9962458412956949},\n {'rougeLsum': 0.9962451340120353}]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Generate text","metadata":{}},{"cell_type":"code","source":"sentence = input()\ntext =  sentence + \" </s>\"\nencoding = tokenizer(text, return_tensors=\"pt\")\ninput_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\noutputs = model.generate(\n    input_ids=input_ids, attention_mask=attention_masks,\n    max_length=1024,\n#     early_stopping=True\n)\nfor output in outputs:\n    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n    print(line)","metadata":{"execution":{"iopub.status.busy":"2024-02-19T03:47:53.561250Z","iopub.execute_input":"2024-02-19T03:47:53.561662Z","iopub.status.idle":"2024-02-19T03:47:56.815591Z","shell.execute_reply.started":"2024-02-19T03:47:53.561628Z","shell.execute_reply":"2024-02-19T03:47:56.814427Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdin","text":" Theo Mundo Deportivo Real Madrid da de danh ao so 10 cho Kylian Mbappe trong truong hop tien dao nguoi Phap cap ben Bernabeu vao he toi Luka Modric dang su dung chiec ao so 10 o Bernabeu nhung tien ve nguoi Croatia gan nhu chac chan se chia tay Los Blancos sau mua giai nay So 7 ma Mbappe thuong mac o PSG hien dang thuoc so huu cua Vinicius\n"},{"name":"stdout","text":"Theo Mundo Deportivo Real Madrid đã để dành áo số 1 cho Kylian Mbappe trong trường hợp tiền đạo người Pháp cập bến Bernabeu vào hè tới Luka Modric đang sử dụng chiếc áo số 10 ở Bernabeu nhưng tiền vệ người Croatia gần như chắc chắn sẽ chia tay Los Blancos sau mùa giải này Số 7 mà Mbappe thường mặc ở PSG hiện đang thuộc sở hữu của Vinicius \n","output_type":"stream"}]}]}